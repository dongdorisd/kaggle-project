{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5193109,"sourceType":"datasetVersion","datasetId":3019493}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-20T01:43:55.944720Z","iopub.execute_input":"2024-12-20T01:43:55.945061Z","iopub.status.idle":"2024-12-20T01:43:56.338492Z","shell.execute_reply.started":"2024-12-20T01:43:55.945033Z","shell.execute_reply":"2024-12-20T01:43:56.337069Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/positive-and-negative-test-cases/Labelled_Test_Cases.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/positive-and-negative-test-cases/Labelled_Test_Cases.csv', encoding='latin1') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T01:45:12.795400Z","iopub.execute_input":"2024-12-20T01:45:12.795822Z","iopub.status.idle":"2024-12-20T01:45:12.830979Z","shell.execute_reply.started":"2024-12-20T01:45:12.795792Z","shell.execute_reply":"2024-12-20T01:45:12.829686Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T01:45:32.611316Z","iopub.execute_input":"2024-12-20T01:45:32.611680Z","iopub.status.idle":"2024-12-20T01:45:32.619983Z","shell.execute_reply.started":"2024-12-20T01:45:32.611648Z","shell.execute_reply":"2024-12-20T01:45:32.618458Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(3000, 5)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T01:45:45.731912Z","iopub.execute_input":"2024-12-20T01:45:45.732325Z","iopub.status.idle":"2024-12-20T01:45:45.752394Z","shell.execute_reply.started":"2024-12-20T01:45:45.732295Z","shell.execute_reply":"2024-12-20T01:45:45.751164Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"    v1                                                 v2 Unnamed: 2  \\\n0  Neg   A customer cannot stream a movie if they purc...        NaN   \n1  Neg   A database management system such as Oracle D...        NaN   \n2  Neg   All credit card information will be not be se...        NaN   \n3  Neg  Not all movies shall be streamed on demand at ...        NaN   \n4  Neg   An employee is unable to successfully use the...        NaN   \n5  Neg   Any interface between a user and the automate...        NaN   \n6  Neg  Table constraints like a Primary key, Foreign ...        NaN   \n7  Neg  File selection dialog does not show supported ...        NaN   \n8  Neg  Field length shown to the user on the page and...        NaN   \n9  Neg  Cancel button functionality is not working in ...        NaN   \n\n  Unnamed: 3 Unnamed: 4  \n0        NaN        NaN  \n1        NaN        NaN  \n2        NaN        NaN  \n3        NaN        NaN  \n4        NaN        NaN  \n5        NaN        NaN  \n6        NaN        NaN  \n7        NaN        NaN  \n8        NaN        NaN  \n9        NaN        NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>Unnamed: 2</th>\n      <th>Unnamed: 3</th>\n      <th>Unnamed: 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Neg</td>\n      <td>A customer cannot stream a movie if they purc...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Neg</td>\n      <td>A database management system such as Oracle D...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Neg</td>\n      <td>All credit card information will be not be se...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Neg</td>\n      <td>Not all movies shall be streamed on demand at ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Neg</td>\n      <td>An employee is unable to successfully use the...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Neg</td>\n      <td>Any interface between a user and the automate...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Neg</td>\n      <td>Table constraints like a Primary key, Foreign ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Neg</td>\n      <td>File selection dialog does not show supported ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Neg</td>\n      <td>Field length shown to the user on the page and...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Neg</td>\n      <td>Cancel button functionality is not working in ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"columns_to_keep = ['v1', 'v2']\ndf = df[columns_to_keep]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T01:46:03.811300Z","iopub.execute_input":"2024-12-20T01:46:03.811722Z","iopub.status.idle":"2024-12-20T01:46:03.818136Z","shell.execute_reply.started":"2024-12-20T01:46:03.811690Z","shell.execute_reply":"2024-12-20T01:46:03.816528Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T01:46:14.524455Z","iopub.execute_input":"2024-12-20T01:46:14.524868Z","iopub.status.idle":"2024-12-20T01:46:14.533864Z","shell.execute_reply.started":"2024-12-20T01:46:14.524838Z","shell.execute_reply":"2024-12-20T01:46:14.532281Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"v1    0\nv2    0\ndtype: int64"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df.v1.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T01:46:25.647080Z","iopub.execute_input":"2024-12-20T01:46:25.647503Z","iopub.status.idle":"2024-12-20T01:46:25.661323Z","shell.execute_reply.started":"2024-12-20T01:46:25.647472Z","shell.execute_reply":"2024-12-20T01:46:25.659962Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"v1\nPos    2100\nNeg     900\nName: count, dtype: int64"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Model Development\n\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Define classifiers\nclassifiers = {\n    'Multinomial Naive Bayes': MultinomialNB(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'Random Forest': RandomForestClassifier(),\n    'Support Vector Machine': SVC(),\n    'Logistic Regression': LogisticRegression()\n}\n\n# Iterate through classifiers\nfor name, clf in classifiers.items():\n    # Build a corpus from the 'Test Case/v2' column\n    corpus = df['v2'].tolist()\n# Create a Bag-of-Words model using CountVectorizer(to convert the text data into numerical features) \n    # and TfidfTransformer(commonly used to normalize and scale the term frequencies)\n    vectorizer = CountVectorizer()\n    transformer = TfidfTransformer()\n    classifier = clf\n\n    # Create a pipeline with a text feature vectorizer (CountVectorizer), TfidfTransformer, and the classifier\n    model = Pipeline([\n        ('vectorizer', vectorizer),\n        ('transformer', transformer),\n        ('classifier', classifier)\n    ])\n # Split the dataset into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(corpus, df['v1'], test_size=0.3, random_state=42)\n\n    # Train the model\n    model.fit(X_train, y_train)\n\n    # Make predictions on the test set\n    predictions = model.predict(X_test)\n\n    # Evaluate the model\n    accuracy = accuracy_score(y_test, predictions)\n    report = classification_report(y_test, predictions)\n\n    print(f'\\nResults for {name}:')\n    print(f'Accuracy: {accuracy}')\n    print('Classification Report:\\n', report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T01:47:52.999505Z","iopub.execute_input":"2024-12-20T01:47:52.999970Z","iopub.status.idle":"2024-12-20T01:47:56.607706Z","shell.execute_reply.started":"2024-12-20T01:47:52.999940Z","shell.execute_reply":"2024-12-20T01:47:56.606318Z"}},"outputs":[{"name":"stdout","text":"\nResults for Multinomial Naive Bayes:\nAccuracy: 0.8\nClassification Report:\n               precision    recall  f1-score   support\n\n         Neg       0.89      0.43      0.58       288\n         Pos       0.78      0.97      0.87       612\n\n    accuracy                           0.80       900\n   macro avg       0.83      0.70      0.72       900\nweighted avg       0.82      0.80      0.78       900\n\n\nResults for Decision Tree:\nAccuracy: 0.9266666666666666\nClassification Report:\n               precision    recall  f1-score   support\n\n         Neg       0.91      0.85      0.88       288\n         Pos       0.93      0.96      0.95       612\n\n    accuracy                           0.93       900\n   macro avg       0.92      0.91      0.91       900\nweighted avg       0.93      0.93      0.93       900\n\n\nResults for Random Forest:\nAccuracy: 0.9066666666666666\nClassification Report:\n               precision    recall  f1-score   support\n\n         Neg       0.94      0.76      0.84       288\n         Pos       0.90      0.98      0.93       612\n\n    accuracy                           0.91       900\n   macro avg       0.92      0.87      0.89       900\nweighted avg       0.91      0.91      0.90       900\n\n\nResults for Support Vector Machine:\nAccuracy: 0.8677777777777778\nClassification Report:\n               precision    recall  f1-score   support\n\n         Neg       0.92      0.64      0.76       288\n         Pos       0.85      0.97      0.91       612\n\n    accuracy                           0.87       900\n   macro avg       0.89      0.81      0.83       900\nweighted avg       0.87      0.87      0.86       900\n\n\nResults for Logistic Regression:\nAccuracy: 0.8655555555555555\nClassification Report:\n               precision    recall  f1-score   support\n\n         Neg       0.96      0.61      0.74       288\n         Pos       0.84      0.99      0.91       612\n\n    accuracy                           0.87       900\n   macro avg       0.90      0.80      0.83       900\nweighted avg       0.88      0.87      0.86       900\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.svm import SVC  # Support Vector Classifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/positive-and-negative-test-cases/Labelled_Test_Cases.csv', encoding='ISO-8859-1')\n\n# Check the first few rows to understand the structure\nprint(df.head())\n\n# Check the first few rows to understand the structure\nprint(df.head())\n\n# Clean the column names (remove any extra spaces or non-ASCII characters)\ndf.columns = df.columns.str.strip()\n\n# Drop unnecessary columns (those with NaN values or irrelevant data)\ndf = df[['v1', 'v2']]  # Keep only the 'label' column and 'text' column\ndf.columns = ['label', 'text']  # Rename columns for clarity\n\n# Check if there are any missing values in the cleaned dataset\nprint(df.isnull().sum())\n\n# Map 'Pos' to 1 and 'Neg' to 0\ndf['label'] = df['label'].map({'Pos': 1, 'Neg': 0})\n\n# Split the dataset into training and testing sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n\n# Build a pipeline to vectorize the text data and train a Support Vector Machine (SVM) classifier\npipeline = Pipeline([\n    ('vectorizer', CountVectorizer()),  # Convert text to a bag-of-words model\n    ('transformer', TfidfTransformer()),  # Optional, but helps with text weighting\n    ('classifier', SVC())  # Support Vector Classifier\n])\n\n# Train the model on the training data\npipeline.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred = pipeline.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy:.4f}')\n\n# Pr\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T01:54:19.613767Z","iopub.execute_input":"2024-12-20T01:54:19.614185Z","iopub.status.idle":"2024-12-20T01:54:20.695721Z","shell.execute_reply.started":"2024-12-20T01:54:19.614154Z","shell.execute_reply":"2024-12-20T01:54:20.694556Z"}},"outputs":[{"name":"stdout","text":"    v1                                                 v2 Unnamed: 2  \\\n0  Neg   A customer cannot stream a movie if they purc...        NaN   \n1  Neg   A database management system such as Oracle D...        NaN   \n2  Neg   All credit card information will be not be se...        NaN   \n3  Neg  Not all movies shall be streamed on demand at ...        NaN   \n4  Neg   An employee is unable to successfully use the...        NaN   \n\n  Unnamed: 3 Unnamed: 4  \n0        NaN        NaN  \n1        NaN        NaN  \n2        NaN        NaN  \n3        NaN        NaN  \n4        NaN        NaN  \n    v1                                                 v2 Unnamed: 2  \\\n0  Neg   A customer cannot stream a movie if they purc...        NaN   \n1  Neg   A database management system such as Oracle D...        NaN   \n2  Neg   All credit card information will be not be se...        NaN   \n3  Neg  Not all movies shall be streamed on demand at ...        NaN   \n4  Neg   An employee is unable to successfully use the...        NaN   \n\n  Unnamed: 3 Unnamed: 4  \n0        NaN        NaN  \n1        NaN        NaN  \n2        NaN        NaN  \n3        NaN        NaN  \n4        NaN        NaN  \nlabel    0\ntext     0\ndtype: int64\nAccuracy: 0.8800\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Import the necessary libraries\nimport pandas as pd\nfrom sklearn.naive_bayes import MultinomialNB  # 导入Multinomial Naive Bayes\nfrom sklearn.tree import DecisionTreeClassifier  # 导入决策树分类器\nfrom sklearn.ensemble import RandomForestClassifier  # 导入随机森林分类器\nfrom sklearn.svm import SVC  # 导入支持向量机分类器\nfrom sklearn.linear_model import LogisticRegression  # 导入逻辑回归分类器\nfrom sklearn.neighbors import KNeighborsClassifier  # 导入KNN分类器\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer  # 导入文本处理工具\nfrom sklearn.model_selection import train_test_split  # 导入数据集划分工具\nfrom sklearn.pipeline import Pipeline  # 导入Pipeline构建工具\nfrom sklearn.metrics import accuracy_score, classification_report  # 导入评估指标\n\n# Define all classifiers, including KNN\nclassifiers = {\n    'Multinomial Naive Bayes': MultinomialNB(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'Random Forest': RandomForestClassifier(),\n    'Support Vector Machine': SVC(),\n    'Logistic Regression': LogisticRegression(),\n    'K-Nearest Neighbors': KNeighborsClassifier()  # 增加KNN分类器\n}\n\n# Read data set\ndf = pd.read_csv('/kaggle/input/positive-and-negative-test-cases/Labelled_Test_Cases.csv', encoding='ISO-8859-1')\n\n# data cleansing\ndf.columns = df.columns.str.strip()  # 去除列名的空格\ndf = df[['v1', 'v2']]  # 只保留'label'和'text'列\ndf.columns = ['label', 'text']  # 重命名列名\ndf['label'] = df['label'].map({'Pos': 1, 'Neg': 0})  # 将标签'Pos'映射为1，'Neg'映射为0\n\n# Divide the training set and the test set (80% training, 20% testing)\nX_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.3, random_state=42)\n\n# Traverse all classifiers\nfor name, clf in classifiers.items():\n    # Create a corpus of textual data\n    corpus = df['text'].tolist()\n    \n    # Create bag models (CountVectorizer) and TF-IDF Transformers (TfidfTransformer)\n    vectorizer = CountVectorizer()\n    transformer = TfidfTransformer()\n    \n    # Create a Pipeline that contains feature extraction and classifier\n    model = Pipeline([\n        ('vectorizer', vectorizer),\n        ('transformer', transformer),\n        ('classifier', clf)\n    ])\n\n    # training model\n    model.fit(X_train, y_train)\n\n    # Make predictions on the test set\n    predictions = model.predict(X_test)\n\n    # evaluation model\n    accuracy = accuracy_score(y_test, predictions)\n    report = classification_report(y_test, predictions)\n\n    print(f'\\nResults for {name}:')\n    print(f'Accuracy: {accuracy}')\n    print('Classification Report:\\n', report)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T08:47:23.646240Z","iopub.execute_input":"2024-12-21T08:47:23.646608Z","iopub.status.idle":"2024-12-21T08:47:26.806309Z","shell.execute_reply.started":"2024-12-21T08:47:23.646578Z","shell.execute_reply":"2024-12-21T08:47:26.805131Z"}},"outputs":[{"name":"stdout","text":"\nResults for Multinomial Naive Bayes:\nAccuracy: 0.8\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.89      0.43      0.58       288\n           1       0.78      0.97      0.87       612\n\n    accuracy                           0.80       900\n   macro avg       0.83      0.70      0.72       900\nweighted avg       0.82      0.80      0.78       900\n\n\nResults for Decision Tree:\nAccuracy: 0.9244444444444444\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.91      0.85      0.88       288\n           1       0.93      0.96      0.95       612\n\n    accuracy                           0.92       900\n   macro avg       0.92      0.90      0.91       900\nweighted avg       0.92      0.92      0.92       900\n\n\nResults for Random Forest:\nAccuracy: 0.9077777777777778\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.93      0.77      0.84       288\n           1       0.90      0.97      0.93       612\n\n    accuracy                           0.91       900\n   macro avg       0.92      0.87      0.89       900\nweighted avg       0.91      0.91      0.91       900\n\n\nResults for Support Vector Machine:\nAccuracy: 0.8677777777777778\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.92      0.64      0.76       288\n           1       0.85      0.97      0.91       612\n\n    accuracy                           0.87       900\n   macro avg       0.89      0.81      0.83       900\nweighted avg       0.87      0.87      0.86       900\n\n\nResults for Logistic Regression:\nAccuracy: 0.8655555555555555\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.96      0.61      0.74       288\n           1       0.84      0.99      0.91       612\n\n    accuracy                           0.87       900\n   macro avg       0.90      0.80      0.83       900\nweighted avg       0.88      0.87      0.86       900\n\n\nResults for K-Nearest Neighbors:\nAccuracy: 0.7944444444444444\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.74      0.55      0.63       288\n           1       0.81      0.91      0.86       612\n\n    accuracy                           0.79       900\n   macro avg       0.78      0.73      0.74       900\nweighted avg       0.79      0.79      0.79       900\n\n","output_type":"stream"}],"execution_count":3}]}